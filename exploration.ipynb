{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General exploration to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('vehicles.csv')\n",
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to start by looking at the categorical variables to see which ones I can potentially use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['condition'].value_counts(dropna=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['size'].value_counts(dropna=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['type'].value_counts(dropna=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['fuel'].value_counts(dropna=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['title_status'].value_counts(dropna=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['transmission'].value_counts(dropna=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histogram of price\n",
    "# Clearly a right-skewed distribution\n",
    "raw_data[raw_data['price'] < 100000]['price'].hist(bins=50, edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = raw_data[(raw_data['price'] < 100000) & (raw_data['odometer'] < 200000)]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(temp['odometer'], temp['price'], alpha=0.2)\n",
    "\n",
    "# Add regression line\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(temp['odometer'], temp['price'])\n",
    "line = slope * temp['odometer'] + intercept\n",
    "plt.plot(temp['odometer'], line, 'r-', label=f'RÂ² = {r_value**2:.3f}')\n",
    "\n",
    "plt.xlabel('Mileage')\n",
    "plt.ylabel('Car Price')\n",
    "plt.title('Car Price vs Mileage')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the exploration above, the columns that seem like the best to keep are the following. I may end up dropping more columns later if they don't add value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['price','year','manufacturer','model','condition','cylinders','fuel','odometer','title_status','transmission','drive','size','type','paint_color','state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(df)\n",
    "total_rows_no_na = len(df.dropna())\n",
    "percentage_rows_dropped = (total_rows - total_rows_no_na) / total_rows * 100\n",
    "\n",
    "print(f'Percentage of rows dropped: {percentage_rows_dropped:.2f}%')\n",
    "print(f'This leaves us with {total_rows_no_na} rows out of {total_rows}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we are dropping a lot of rows, since these rows are quality, we still have more than enough data to make a good model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only manufacturers with more than 1000 cars. Don't wan to handle rare cases.\n",
    "manufacturers = df['manufacturer'].value_counts()\n",
    "manufacturers = manufacturers[manufacturers > 1000]\n",
    "df = df[df['manufacturer'].isin(manufacturers.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9 ]', '', text) \n",
    "    text = re.sub(r'\\s+', ' ', text).strip() \n",
    "    return text\n",
    "df['model_clean'] = df['model'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_counts = df['model_clean'].value_counts()\n",
    "common_models = model_counts[model_counts >= 100].index\n",
    "df = df[df['model_clean'].isin(common_models)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Make and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, I originally tried modeling based off of \"size\" and \"type\" and \"manufacturer\", so \"Ford Mid-Sized SUV\". While this actually worked pretty well, that is not how people search for cars. They search for makes/models. So even though it wasn't perfect, I decided to clean up the make and model and just drop the makes and models that weren't very common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_model(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9 ]', '', text) \n",
    "    text = re.sub(r'\\s+', ' ', text).strip() \n",
    "    return text\n",
    "\n",
    "df['cleaned_model'] = df['model'].apply(clean_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    # Ford models\n",
    "    'f150',\n",
    "    'escape',\n",
    "    'explorer',\n",
    "    'f250',\n",
    "    'mustang',\n",
    "    'fusion',\n",
    "    'focus',\n",
    "    'f350',\n",
    "    'edge',\n",
    "    'expedition',\n",
    "    # Chevrolet models\n",
    "    'silverado',\n",
    "    'equinox',\n",
    "    'malibu',\n",
    "    'tahoe',\n",
    "    'corvette',\n",
    "    'impala',\n",
    "    'cruze',\n",
    "    'camaro',\n",
    "    'suburban',\n",
    "    'traverse',\n",
    "    # Toyota models\n",
    "    'camry',\n",
    "    'tacoma',\n",
    "    'corolla',\n",
    "    'rav4',\n",
    "    'prius',\n",
    "    'tundra',\n",
    "    '4runner',\n",
    "    'sienna',\n",
    "    'highlander',\n",
    "    # Honda models\n",
    "    'accord',\n",
    "    'civic',\n",
    "    'crv',\n",
    "    'odyssey',\n",
    "    'pilot',\n",
    "    # Nissan models\n",
    "    'altima',\n",
    "    'rogue',\n",
    "    'sentra',\n",
    "    'maxima',\n",
    "    'pathfinder',\n",
    "    'versa',\n",
    "    'murano',\n",
    "    'frontier',\n",
    "    # Jeep models\n",
    "    'wrangler',\n",
    "    'grand cherokee', # Important this is before cherokee for matching\n",
    "    'cherokee',\n",
    "    'liberty',\n",
    "    'patriot',\n",
    "    'compass',\n",
    "    # Ram models\n",
    "    '1500',\n",
    "    '2500',\n",
    "    '3500',\n",
    "    # GMC models\n",
    "    'sierra',\n",
    "    'acadia',\n",
    "    'yukon',\n",
    "    'terrain',\n",
    "    # Note: Left BMW off since naming conditions are too varied\n",
    "    # Dodge models\n",
    "    'charger',\n",
    "    'grand caravan',\n",
    "    'challenger',\n",
    "    'durango',\n",
    "    'journey',\n",
    "    # Mercedes-Benz models\n",
    "    'cclass',\n",
    "    'eclass',\n",
    "    'sclass',\n",
    "    # Hyundai models\n",
    "    'sonata',\n",
    "    'elantra',\n",
    "    'santa fe',\n",
    "    'tucson',\n",
    "    # Subaru models\n",
    "    'outback',\n",
    "    'forester',\n",
    "    'impreza',\n",
    "    'legacy',\n",
    "    # Volkswagen models\n",
    "    'jetta',\n",
    "    'passat',\n",
    "    'tiguan',\n",
    "    # Kia models\n",
    "    'soul',\n",
    "    'optima',\n",
    "    'sorento',\n",
    "    'forte', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['base_model'] = 'other' \n",
    "for model in models:\n",
    "    mask = df['cleaned_model'].str.contains(model, case=False, na=False)\n",
    "    df.loc[mask, 'base_model'] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These cars over 1 million dollars are clearly mislabeled\n",
    "df[df['price'] >1000000].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['odometer'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly some cars were mislabeled with price. I will be using 2.5 times the IQR to detect outliers for price and odometer. If this range goes below 0, may need to filter out 0 manually since this wouldn't make since for either column. For year I will be setting a cutoff manually since I know vintage cars can do the inverse in what we normally see in price and that is not what this model is going to be focused on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
